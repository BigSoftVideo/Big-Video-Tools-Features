# Big-Video-Tools-Features
This repository is a collection point for ideas, wishes and suggestions for tools and features to enhance the Big Video workflow for qualitative video analysis.
We use our BigSoftVideo space in GitHub to develop software tools to support Big Video. Most of the coding we do is private until a robust beta is released publicly.
The software development team is led by Paul McIlvenny and Jacob Davidsen. Programmers who have worked on BigSoftVideo projects include Nicklas Haagh Christensen, Stefan Tanderup, Andreas Hejndorf and Artúr Barnabas Kovács.
We have four ongoing software projects at various stages of development:
1. *AVA360VR* (Annotate, Visualise, Analyse 360 video in VR) - Stage 5 refactor soon ready for live beta-testing [HTC Vive/Vive Pro Win10]
2. *CAVA360VR* (Collaborate, Annotate, Visualise, Analyse 360 video in VR) multi-user - Stage 3 ready in beta-testing for live data sessions [HTC Vive/Vive Pro Win10]
3. *SQUIVE* (Staging QUalitative Immersive Virtualisation Engine) - Stage 3 refactor beta [HTC Vive/Vive Pro Win10]
4. *DOTE* (Distributed Open Transcription Environment) - Stage 2 refactor alpha [Win10/macOS]

We are always interested in ideas and suggestions for tools and features that will support the Big Video workflow of qualitative video analysis. You may have seen a demo of one of our tools in beta, read one of our papers, or you may have strong feelings about some of the software tools currently available for transcription and qualitative analysis (eg. TRANSANA, ELAN, CLAN, ANVIL, etc). If you would like to share with us, then add them as an issue here in this repository (click in the menu above). You will have to create an account with GitHub to do so. Describe your suggestion or request in as much detail as you wish. Include sketches or images if you wish. You can respond to other issues and add emojis to indicate your assessment and/or support. 
